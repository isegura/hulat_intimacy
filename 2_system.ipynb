{"cells":[{"cell_type":"markdown","metadata":{"id":"RzW071GVi7AT"},"source":["# Transformer models with data augmented for Intimacy scoring\n","\n","Task: https://codalab.lisn.upsaclay.fr/competitions/7096\n","\n","This notebook contains the code to fine-tune several pre-trained transformers for the task of intimacy analysis (regression). \n","\n","In particular, the models are:\n","\n","- **BERT Multilingual**: bert-base-multilingual-uncased\n","- **XLM-T**: This is a XLM-Roberta-base model trained on ~198M multilingual tweets. MODEL_NAME= \"cardiffnlp/twitter-xlm-roberta-base\"\n","\n","- **XLM-R**: XLM-RoBERTa model pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. MODEL_NAME= \"xlm-roberta-base\"\n","\n","- **DistillBERT**: a distilled version of the BERT base multilingual model. \n","- **MiniLM**: Multilingual MiniLM uses the same tokenizer as XLM-R. MODEL_NAME= \"microsoft/Multilingual-MiniLM-L12-H384\"\n","\n","\n","Experiments show that XLM-T obtains the best results. We have also explore the use of data augmentation techniques such as EDA or NLPAug library. Unfortunately, data augmentation does no seem to improve the results. In the final submission, we sent XLM-T with data augmentation. \n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zM8pVjHVtHMA"},"source":["## Defining some global variables\n","Select the model, if we use data augmented or if we are preparing for submission:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1676844638890,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"-NKHM9HCtIpx","outputId":"4a62d489-5c35-4578-a7d8-b0287841bfbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using model: microsoft/Multilingual-MiniLM-L12-H384 True\n"]}],"source":["USE_DATA_AUGMENTED = True\n","\n","models= ['bert-base-multilingual-uncased', \n","         'cardiffnlp/twitter-xlm-roberta-base', \n","         'xlm-roberta-base', \n","         'distilbert-base-multilingual-cased', \n","         'microsoft/Multilingual-MiniLM-L12-H384']\n","MODEL_NAME=models[4] #0, 1, 2, 3, 4\n","\n","print('Using model:', MODEL_NAME, USE_DATA_AUGMENTED)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nGR1YAeaQa7c"},"source":["Let's check if we are using gpu:"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":866,"status":"ok","timestamp":1676844640067,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"5mZWztnvQeQy","outputId":"7833d7dc-61c5-494c-b3eb-c803ab2b1476"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Feb 19 22:10:39 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    32W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8932,"status":"ok","timestamp":1676844648995,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"QUwjN1U5IJfv","outputId":"25d0b48d-9c33-4567-cb97-1d28cf465c62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.9.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install datasets transformers"]},{"cell_type":"markdown","metadata":{"id":"yo1DQMpMyWWR"},"source":["## Data\n","\n","We will use the mint dataset that consits of a collection of tweets. Each tweets is annotated with a intimacy score. The task is to predict the intimacy score for a given tweet.\n"]},{"cell_type":"markdown","metadata":{"id":"wa7haywYz0GZ"},"source":["### Loading the data and the augmented data\n","\n","The organizers have only provided a csv with the full training. We have already split the dataset into splits and save them to huggingface. \n","So, instead of loading the dataset from local,  we load the dataset from huggingface. \n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301,"referenced_widgets":["16b6e0678a414f4f8a76e79cc8e7fcca","f360e9f6127e4ab38637638c4f9ed8dd","1e612c4484ca4efc95ed0609358ae0cc","37fd272053374b0ab3c6f74d0178597b","0db97eb6aed844f1a646e86cc78c6d5b","c86ac0588aef4b76bb6ffe5b4fd2d961","bcb979f18d884e0192af5ee16b112356","0c8b2dbe8bc3447885e4417d93eea0f3","91e6fa7e29cb4f47b1f53bc52dca36c7","c5992451189b4b15810704fdd04c28e1","a822fc216cea44189832eca201809ac4"]},"executionInfo":{"elapsed":2337,"status":"ok","timestamp":1676844651326,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"qR_LQm-ui_EK","outputId":"0fe804a8-c744-4411-96b9-94b9d8766b8e"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Using custom data configuration ISEGURA--intimacy_aug_all-2b3d9b7cf530bc6d\n","WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/ISEGURA___csv/ISEGURA--intimacy_aug_all-2b3d9b7cf530bc6d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16b6e0678a414f4f8a76e79cc8e7fcca"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ISEGURA/intimacy_aug_all was loaded!!!\n"]},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'language'],\n","        num_rows: 22749\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label', 'language'],\n","        num_rows: 1908\n","    })\n","})"]},"metadata":{},"execution_count":4}],"source":["from datasets import load_dataset, concatenate_datasets\n","\n","dataset_name = \"ISEGURA/mint\"\n","access_token=\"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\"\n","\n","if USE_DATA_AUGMENTED:\n","    dataset_name = \"ISEGURA/intimacy_aug_all\"\n","\n","dataset = load_dataset(dataset_name, use_auth_token=access_token) #use_auth_token=True, for public datasets\n","print(dataset_name, \"was loaded!!!\")\n","\n","dataset['train'] = concatenate_datasets([dataset['train'], dataset['validation']])\n","dataset['validation'] = dataset['test']\n","del(dataset['test'])\n","\n","if USE_DATA_AUGMENTED:\n","    dataset['validation'] = dataset['validation'].remove_columns(['text_aug', 'text_nlpaug'])\n","\n","    # we get the augmented texts and save them into new datasets\n","    data_eda = dataset['train'].remove_columns(['text','text_nlpaug']).rename_columns({'text_aug':'text'})\n","    data_nlpaug = dataset['train'].remove_columns(['text','text_aug']).rename_columns({'text_nlpaug':'text'})\n","    dataset[\"train\"] = dataset[\"train\"].remove_columns([ 'text_aug', 'text_nlpaug'])\n","    dataset[\"train\"] = concatenate_datasets([dataset[\"train\"],data_eda, data_nlpaug])\n","\n","    del(data_eda)\n","    del(data_nlpaug)\n","\n","LANGUAGES = set(dataset['train']['language'])\n","\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"xS8_R_qnjoWO"},"source":["Let's clean the texts removing some strings:"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1676844651326,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"5DmozTCJedjd","outputId":"feb9b512-5b88-4e17-aae6-90af20fce46a"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/ISEGURA___csv/ISEGURA--intimacy_aug_all-2b3d9b7cf530bc6d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-a62bf673c302cad3.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/ISEGURA___csv/ISEGURA--intimacy_aug_all-2b3d9b7cf530bc6d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-908010e12c67df06.arrow\n"]},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'language'],\n","        num_rows: 22749\n","    })\n","    validation: Dataset({\n","        features: ['text', 'label', 'language'],\n","        num_rows: 1908\n","    })\n","})"]},"metadata":{},"execution_count":5}],"source":["import re\n","def clean(examples):\n","    ## it applies the tokenzier on the dataset in its field text\n","    # we could add max_length = MAX_LENGHT, but in this case is not neccesary because MAX_LENTH is already 512, the maximum length allowed by the model\n","    new_texts = []\n","    for text in examples['text']:\n","        text = re.sub('@user', '', text)\n","        text = re.sub('http', '', text)\n","        text = re.sub('@[\\w]+', '', text)\n","        text = text.strip()\n","        new_texts.append(text)\n","    \n","    examples['text'] = new_texts\n","    return examples\n","\n","dataset=dataset.map(clean, batched=True)\n","dataset\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Q8t1hxs_JaIc"},"source":["### Tokenization\n","\n","We will load a tokenizer from a pre-trained model. This tokenizer allows us to trasform the input texts to the required format for fine-tuning the pre-trained model.\n","In particular, we will work with the 'bert-base-multilingual-uncased', because it is a multilingual model and our input texts are written in several languages:"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5792,"status":"ok","timestamp":1676844657112,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"yUHxfHjdt7nQ"},"outputs":[],"source":["from transformers import AutoTokenizer\n","if 'MiniLM' in MODEL_NAME:\n","    # we must load the tokenizer of XLM-R\n","    tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n","else: \n","    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n"]},{"cell_type":"markdown","metadata":{"id":"-BqwiM9VSEKD"},"source":["### Maximum length of texts\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10862,"status":"ok","timestamp":1676844667970,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"n6dWEX0ISMD8","outputId":"4898939e-c3f5-4109-afcc-6ef1d1f21697"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    22749.000000\n","mean        24.856082\n","std         24.175190\n","min          2.000000\n","25%         12.000000\n","50%         19.000000\n","75%         29.000000\n","85%         36.000000\n","90%         42.000000\n","95%         58.000000\n","99%        140.000000\n","max        291.000000\n","dtype: float64"]},"metadata":{},"execution_count":7}],"source":["import pandas as pd\n","\n","len_train_texts = [len(tokenizer(text).input_ids) for text in dataset['train']['text']]\n","df=pd.Series(len_train_texts)\n","# free the space of this list\n","del(len_train_texts)\n","#show the statistics\n","df.describe(percentiles=[0.25, 0.50, 0.75, 0.85, 0.90, 0.95, 0.99])\n"]},{"cell_type":"markdown","metadata":{"id":"phIhJDqR-nkG"},"source":["Therefore, we can consider as maximum length 50, because it will cover the most sequences."]},{"cell_type":"markdown","metadata":{"id":"U0g21yX3KPXw"},"source":["### Data encoding\n","\n","\n","TODO: Review dynamic padding.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265,"referenced_widgets":["1bfda8d2bbe542e7b5a8102c558da71c","f0dfd674aeef45b49ce12b33b0b900ff","ba4cb3603a454a91b4c32ac5aad437f3","160dfb30daa54813937ed195b4a75e6b","4b82bb7543c14b88a5f5f0bce4cd69ec","7b13ee6cbc8a4805b07aac652752ccbe","bcdd152762ee49ab81bdc96bc5a26213","fef91142e4aa44a78350a40345dfdb32","61d9fe422df94b77b202dd30b9a40612","5ac65ad1bf2c4beebee22fb52bd5605a","33f73846515b4e8daf17012cb2418f59"]},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1676844667970,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"GeiPcTYbYss0","outputId":"956c5a6d-5b53-4530-d41f-36959407babd"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/ISEGURA___csv/ISEGURA--intimacy_aug_all-2b3d9b7cf530bc6d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-97a3eb97e2d367c4.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bfda8d2bbe542e7b5a8102c558da71c"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['label', 'input_ids', 'attention_mask'],\n","        num_rows: 22749\n","    })\n","    validation: Dataset({\n","        features: ['label', 'input_ids', 'attention_mask'],\n","        num_rows: 1908\n","    })\n","})"]},"metadata":{},"execution_count":8}],"source":["MAX_LEN = 50\n","\n","def tokenize(examples):\n","    ## it applies the tokenzier on the dataset in its field text\n","    # we could add max_length = MAX_LENGHT, but in this case is not neccesary because MAX_LENTH is already 512, the maximum length allowed by the model\n","    return tokenizer(examples[\"text\"], truncation=True, max_length=MAX_LEN, padding='max_length')\n","\n","#apply tokenizer and remove the columns that we do not need anymore\n","data_encodings=dataset.map(tokenize, batched=True, remove_columns=['text','language'])\n","data_encodings\n"]},{"cell_type":"markdown","metadata":{"id":"zuJid5TyKbZP"},"source":["## Model\n","\n","We load the pre-trained model. \n","\n","In this case, the **number of labels to be predicted will be only 1**, because it is not a classification task, but rather **a regression problem**. \n","\n","As num_labes is 1, the **AutoModelForSequenceClassification will trigger the linear regression and use MSELoss() as the loss function** automatically. \n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12910,"status":"ok","timestamp":1676844680628,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"_hwlj2ClIccQ","outputId":"4914ec20-762b-41c2-d9a9-b5267fcff205"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/Multilingual-MiniLM-L12-H384 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification\n","# As num_labes is 1, the AutoModelForSequenceClassification will trigger the linear regression and use MSELoss() as the loss function automatically.\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels = 1).to(\"cuda\")\n"]},{"cell_type":"markdown","metadata":{"id":"yQ_vPRQbaRNm"},"source":["Anyway, we define a function to compute the appropiate metrics for regression:"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":850,"status":"ok","timestamp":1676844681455,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"Dwu4vVdXaQFc"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n","from scipy import stats\n","\n","def compute_metrics_for_regression(eval_pred):\n","    logits, labels = eval_pred\n","    labels = labels.reshape(-1, 1)\n","\n","    # loss metrics\n","    mse = mean_squared_error(labels, logits)\n","    rmse = mean_squared_error(labels, logits, squared=False)\n","    mae = mean_absolute_error(labels, logits)\n","    smape = 1/len(labels) * np.sum(2 * np.abs(logits-labels) / (np.abs(labels) + np.abs(logits))*100)\n","    # performance metrics\n","    r2 = r2_score(labels, logits)\n","    pearson=stats.pearsonr(np.squeeze(np.asarray(labels)), np.squeeze(np.asarray(logits)))\n","    pearson=pearson[0]\n","    # we return a dictionary with all metrics\n","    return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"smape\": smape, \"pearson\": pearson}\n","    # return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"smape\": smape}"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1676844681456,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"VIsQANsLadcI"},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","NUM_EPOCHS = 3 # paper used 15\n","\n","# Specifiy the arguments for the trainer  \n","training_args = TrainingArguments(\n","    output_dir ='./results',          \n","    num_train_epochs = NUM_EPOCHS,     \n","    per_device_train_batch_size = 64, # 128 in the paper   \n","    per_device_eval_batch_size = 20,   \n","    weight_decay = 0.01,               \n","    learning_rate = 2e-5,  # 0.001 in the paper,\n","    logging_dir = './logs',            \n","    save_total_limit = 10,\n","    load_best_model_at_end = True,     \n","    # metric_for_best_model = 'rmse',    \n","    metric_for_best_model = 'pearson',     \n","    evaluation_strategy = \"epoch\",  # steps in the paper\n","    save_strategy = \"epoch\",    # steps in the paper\n","    report_to = 'all',\n",") "]},{"cell_type":"markdown","metadata":{"id":"G3O3vBGJay-K"},"source":["### Trainer"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":885},"executionInfo":{"elapsed":258961,"status":"ok","timestamp":1676844940404,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"_e49IBoea0xj","outputId":"59b286ce-cd31-4f8f-bf82-23d87d046cc2"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 22749\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1068\n","  Number of trainable parameters = 117654145\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1068' max='1068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1068/1068 04:16, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Mse</th>\n","      <th>Rmse</th>\n","      <th>Mae</th>\n","      <th>R2</th>\n","      <th>Smape</th>\n","      <th>Pearson</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.543569</td>\n","      <td>0.543569</td>\n","      <td>0.737271</td>\n","      <td>0.571749</td>\n","      <td>0.308945</td>\n","      <td>27.905501</td>\n","      <td>0.564143</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.026600</td>\n","      <td>0.506707</td>\n","      <td>0.506707</td>\n","      <td>0.711834</td>\n","      <td>0.544076</td>\n","      <td>0.355809</td>\n","      <td>26.532910</td>\n","      <td>0.603266</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.502800</td>\n","      <td>0.504197</td>\n","      <td>0.504197</td>\n","      <td>0.710068</td>\n","      <td>0.558034</td>\n","      <td>0.359000</td>\n","      <td>27.231218</td>\n","      <td>0.609097</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 1908\n","  Batch size = 20\n","Saving model checkpoint to ./results/checkpoint-356\n","Configuration saved in ./results/checkpoint-356/config.json\n","Model weights saved in ./results/checkpoint-356/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 1908\n","  Batch size = 20\n","Saving model checkpoint to ./results/checkpoint-712\n","Configuration saved in ./results/checkpoint-712/config.json\n","Model weights saved in ./results/checkpoint-712/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 1908\n","  Batch size = 20\n","Saving model checkpoint to ./results/checkpoint-1068\n","Configuration saved in ./results/checkpoint-1068/config.json\n","Model weights saved in ./results/checkpoint-1068/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from ./results/checkpoint-1068 (score: 0.609097179407145).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1068, training_loss=0.7474650550870859, metrics={'train_runtime': 258.6382, 'train_samples_per_second': 263.871, 'train_steps_per_second': 4.129, 'total_flos': 439017138170100.0, 'train_loss': 0.7474650550870859, 'epoch': 3.0})"]},"metadata":{},"execution_count":12}],"source":["from transformers import Trainer\n","\n","# Call the Trainer\n","trainer = Trainer(\n","    model = model,                         \n","    args = training_args,                  \n","    train_dataset = data_encodings['train'], # if you only want to check the training is right, replace with train_dataset = data_encodings['train'].select(range(100))         \n","    eval_dataset = data_encodings['validation'],  # if you only want to check the training is right, replace with eval_dataset = data_encodings['validation'].select(range(20)),                  \n","    compute_metrics = compute_metrics_for_regression,     \n","    #callbacks=[EarlyStoppingCallback(3, 0.0)]\n",")\n","\n","# Train the model\n","trainer.train()\n"]},{"cell_type":"markdown","metadata":{"id":"hlfn4lLudjEU"},"source":["### Evaluate on the validation dataset\n","The best model will be evaluated on the validation dataset:"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"elapsed":2021,"status":"ok","timestamp":1676844942396,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"wMlIl0xBayJC","outputId":"c25e6e96-7fbd-40cc-b80c-0e84e23a6652"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 1908\n","  Batch size = 20\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [96/96 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.5041967034339905,\n"," 'eval_mse': 0.5041967034339905,\n"," 'eval_rmse': 0.7100681066513062,\n"," 'eval_mae': 0.5580341815948486,\n"," 'eval_r2': 0.3589999894583933,\n"," 'eval_smape': 27.23121806210692,\n"," 'eval_pearson': 0.609097179407145,\n"," 'eval_runtime': 2.0694,\n"," 'eval_samples_per_second': 922.002,\n"," 'eval_steps_per_second': 46.39,\n"," 'epoch': 3.0}"]},"metadata":{},"execution_count":13}],"source":["trainer.evaluate()"]},{"cell_type":"markdown","metadata":{"id":"j5hzAbXtLXV4"},"source":["## Evaluation\n","\n","However, the model could be direcly used to predict the scores for the texts the test dataset and then obtain the metrics on the test dataset to provide a final evaluation. \n"]},{"cell_type":"markdown","metadata":{"id":"B_PsourCtPFs"},"source":["### Predictions"]},{"cell_type":"markdown","metadata":{"id":"3st4i0a4xNl5"},"source":["The following funcion gests a text (which is not tokenized or encoded) and returns the predicted intimacy score provided by the model. \n","To do this, the functions needs to encode the text by using the same tokenizer and arguments that were used to transform the training and validation dataset. Then, the model is used directly on the encoded input. The output of the model is a tensor containing the value of the predicted scoring. We finally return this value. "]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1676844942397,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"},"user_tz":-60},"id":"7yEhoWvcgoXL"},"outputs":[],"source":["def get_prediction(text):\n","    # prepare our text into tokenized sequence\n","    inputs = tokenizer(text, max_length=MAX_LEN, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model(**inputs)   #output is a tensor\n","    return outputs[0].item()    #we only have to return the value of the tensor by using item()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140,"referenced_widgets":["1501f8c23bda478faf76ab6c00192bfa","018cf99e17244144afab89b419287cb2","5b769449b44442c08eb900cda0ded791","31abaa63db0e47b4bf486f79fcff8b13","c58375265d184c83b18a173ef4e0bdf4","eb64a0250cac46aba3d1642370f0c05e","6499cc6284264ca18b6e5de33b81abec","a28152b899944875a260feb2ebb82864","7a4444089a7646f7bdbec19212b178f0","dc466c9eba0e4dbca1354f1b82f5ac81","540112ec3820426ebcdc1150cc930348"]},"id":"bvO2aQ0Yp3x4","executionInfo":{"status":"ok","timestamp":1676845001021,"user_tz":-60,"elapsed":58630,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"db2bb19f-f146-4cfb-d64d-cf3ffc6d850b"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Using custom data configuration default-e1cbdb9d865648ca\n","WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-e1cbdb9d865648ca/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1501f8c23bda478faf76ab6c00192bfa"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-e1cbdb9d865648ca/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-2eb053fb9ff468e6.arrow\n"]}],"source":["from google.colab import drive\n","\n","# mount your google drive\n","drive.mount('/content/drive')\n","\n","PATH = \"/content/drive/My Drive/Colab Notebooks/proyectos/intimacy/\"\n","PATH_DATA = \"/content/drive/My Drive/Colab Notebooks/data/intimacy/\"\n","\n","dataset_test = load_dataset(\"csv\", data_files=PATH_DATA+\"test_labeled.csv\")\n","# clean the texts in the test dataset \n","# as we used for the texts in the training dataset\n","dataset_test=dataset_test.map(clean, batched=True)\n","dataset_test = dataset_test['train']\n","y_test = dataset_test['label']\n","\n","# generate predictions for each text\n","y_pred=[get_prediction(text) for text in dataset_test['text']]\n","\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = mean_squared_error(y_test, y_pred, squared=False)\n","mae = mean_absolute_error(y_test, y_pred)\n","diff = [e1 - e2 for e1, e2 in zip(y_pred,y_test)] # Resultado: [-2, -1, -2, 0, -7, 6, 2]\n","smape = 1/len(y_test) * np.sum(2 * np.abs(diff) / (np.abs(y_test) + np.abs(y_pred))*100)\n","# performance metrics\n","r2 = r2_score(y_test, y_pred)\n","pearson=stats.pearsonr(np.squeeze(np.asarray(y_test)), np.squeeze(np.asarray(y_pred)))\n","pearson=pearson[0]\n","\n","results = {'mse': mse, 'rmse': rmse, 'mae': mae,\n","           'smape':smape, 'r2':r2, 'pearson':pearson}\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTUKdnoWcgtk","executionInfo":{"status":"ok","timestamp":1676845001022,"user_tz":-60,"elapsed":26,"user":{"displayName":"ISABEL SEGURA BEDMAR","userId":"10362143810849156637"}},"outputId":"71d613b7-f7aa-4ced-88fd-fa554ea72174"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/proyectos/intimacy/results/Multilingual-MiniLM-L12-H384_aug.csv  was saved!\n"]}],"source":["import os\n","### Create an output directory\n","output_dir = PATH+'results/'\n","if not os.path.exists(output_dir): ### If the file directory doesn't already exists,\n","    os.makedirs(output_dir) ### Make it please\n","\n","# we use the test split to obtain final results\n","df = pd.DataFrame.from_dict(results.items())\n","\n","# saving to csv\n","if '/' in MODEL_NAME:\n","    MODEL_NAME = MODEL_NAME[MODEL_NAME.index('/')+1:]\n","\n","path_results = output_dir+MODEL_NAME\n","if USE_DATA_AUGMENTED:\n","    path_results += '_aug'\n","path_results += '.csv'\n","\n","df.to_csv(path_results, index= True)\n","\n","print(path_results, ' was saved!')\n"]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyOboYmbV96OqzVyn/6YwVx0"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"16b6e0678a414f4f8a76e79cc8e7fcca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f360e9f6127e4ab38637638c4f9ed8dd","IPY_MODEL_1e612c4484ca4efc95ed0609358ae0cc","IPY_MODEL_37fd272053374b0ab3c6f74d0178597b"],"layout":"IPY_MODEL_0db97eb6aed844f1a646e86cc78c6d5b"}},"f360e9f6127e4ab38637638c4f9ed8dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c86ac0588aef4b76bb6ffe5b4fd2d961","placeholder":"​","style":"IPY_MODEL_bcb979f18d884e0192af5ee16b112356","value":"100%"}},"1e612c4484ca4efc95ed0609358ae0cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c8b2dbe8bc3447885e4417d93eea0f3","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91e6fa7e29cb4f47b1f53bc52dca36c7","value":3}},"37fd272053374b0ab3c6f74d0178597b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5992451189b4b15810704fdd04c28e1","placeholder":"​","style":"IPY_MODEL_a822fc216cea44189832eca201809ac4","value":" 3/3 [00:00&lt;00:00, 79.58it/s]"}},"0db97eb6aed844f1a646e86cc78c6d5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c86ac0588aef4b76bb6ffe5b4fd2d961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcb979f18d884e0192af5ee16b112356":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c8b2dbe8bc3447885e4417d93eea0f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91e6fa7e29cb4f47b1f53bc52dca36c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5992451189b4b15810704fdd04c28e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a822fc216cea44189832eca201809ac4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bfda8d2bbe542e7b5a8102c558da71c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0dfd674aeef45b49ce12b33b0b900ff","IPY_MODEL_ba4cb3603a454a91b4c32ac5aad437f3","IPY_MODEL_160dfb30daa54813937ed195b4a75e6b"],"layout":"IPY_MODEL_4b82bb7543c14b88a5f5f0bce4cd69ec"}},"f0dfd674aeef45b49ce12b33b0b900ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b13ee6cbc8a4805b07aac652752ccbe","placeholder":"​","style":"IPY_MODEL_bcdd152762ee49ab81bdc96bc5a26213","value":"100%"}},"ba4cb3603a454a91b4c32ac5aad437f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fef91142e4aa44a78350a40345dfdb32","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61d9fe422df94b77b202dd30b9a40612","value":2}},"160dfb30daa54813937ed195b4a75e6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ac65ad1bf2c4beebee22fb52bd5605a","placeholder":"​","style":"IPY_MODEL_33f73846515b4e8daf17012cb2418f59","value":" 2/2 [00:00&lt;00:00,  5.16ba/s]"}},"4b82bb7543c14b88a5f5f0bce4cd69ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b13ee6cbc8a4805b07aac652752ccbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcdd152762ee49ab81bdc96bc5a26213":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fef91142e4aa44a78350a40345dfdb32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61d9fe422df94b77b202dd30b9a40612":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ac65ad1bf2c4beebee22fb52bd5605a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33f73846515b4e8daf17012cb2418f59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1501f8c23bda478faf76ab6c00192bfa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_018cf99e17244144afab89b419287cb2","IPY_MODEL_5b769449b44442c08eb900cda0ded791","IPY_MODEL_31abaa63db0e47b4bf486f79fcff8b13"],"layout":"IPY_MODEL_c58375265d184c83b18a173ef4e0bdf4"}},"018cf99e17244144afab89b419287cb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb64a0250cac46aba3d1642370f0c05e","placeholder":"​","style":"IPY_MODEL_6499cc6284264ca18b6e5de33b81abec","value":"100%"}},"5b769449b44442c08eb900cda0ded791":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a28152b899944875a260feb2ebb82864","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a4444089a7646f7bdbec19212b178f0","value":1}},"31abaa63db0e47b4bf486f79fcff8b13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc466c9eba0e4dbca1354f1b82f5ac81","placeholder":"​","style":"IPY_MODEL_540112ec3820426ebcdc1150cc930348","value":" 1/1 [00:00&lt;00:00, 36.15it/s]"}},"c58375265d184c83b18a173ef4e0bdf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb64a0250cac46aba3d1642370f0c05e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6499cc6284264ca18b6e5de33b81abec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a28152b899944875a260feb2ebb82864":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a4444089a7646f7bdbec19212b178f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc466c9eba0e4dbca1354f1b82f5ac81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"540112ec3820426ebcdc1150cc930348":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}